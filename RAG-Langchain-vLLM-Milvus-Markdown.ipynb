{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a331fd6",
   "metadata": {},
   "source": [
    "## RAG example with Langchain, Milvus, and vLLM\n",
    "\n",
    "Requirements:\n",
    "- A Milvus instance, either standalone or cluster.\n",
    "- Connection credentials to Milvus must be available as environment variables: MILVUS_USERNAME and MILVUS_PASSWORD.\n",
    "- A vLLM inference endpoint. In this example we use the OpenAI Compatible API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712b3e8-f406-4387-9188-3e2f20a6841f",
   "metadata": {},
   "source": [
    "### Needed packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a359bd-4f69-4e88-82c0-5763c26aa0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q einops==0.7.0 langchain==0.1.9 pymilvus==2.3.6 sentence-transformers==2.4.0 openai==1.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e11d23-c0ad-4875-b67f-149fc8b14725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd4537b",
   "metadata": {},
   "source": [
    "#### Bases parameters, Inference server and Milvus info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51baf1a6-4111-4b40-b43a-833438bdc222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace values according to your Milvus deployment (including the proper Milvus Collection name)\n",
    "INFERENCE_SERVER_URL = \"http://vllm.vllm.svc.cluster.local:8000/v1\"\n",
    "MODEL_NAME = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "MAX_TOKENS=1024\n",
    "TOP_P=0.95\n",
    "TEMPERATURE=0.01\n",
    "PRESENCE_PENALTY=1.03\n",
    "MILVUS_HOST = \"vectordb-milvus.milvus.svc.cluster.local\"\n",
    "MILVUS_PORT = 19530\n",
    "MILVUS_USERNAME = \"root\"\n",
    "MILVUS_PASSWORD = \"Milvus\"\n",
    "MILVUS_COLLECTION = \"catalogo_ba_gov\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c1b1a",
   "metadata": {},
   "source": [
    "#### Initialize the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb6a3e3-5ccd-441e-b80d-427555d9e9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 2.4.0.dev0, however, your version is 2.4.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "/opt/app-root/src/.cache/huggingface/modules/transformers_modules/nomic-ai/nomic-bert-2048/40b98394640e630d5276807046089b233113aa87/modeling_hf_nomic_bert.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = loader(resolved_archive_file)\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = {'trust_remote_code': True}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT, \"user\": MILVUS_USERNAME, \"password\": MILVUS_PASSWORD},\n",
    "    collection_name=MILVUS_COLLECTION,\n",
    "    metadata_field=\"metadata\",\n",
    "    text_field=\"page_content\",\n",
    "    drop_old=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a3a2b",
   "metadata": {},
   "source": [
    "#### Initialize query chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8fd396-0798-45c5-8969-6b6ede134c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST] <<SYS>>\n",
    "Você é um assistente prestativo que deve apenas responder as perguntas fornecidas.\n",
    "\n",
    "Você receberá uma pergunta que precisa responder, juntamente com um contexto que fornecerá informações. Você deve responder à pergunta com base nesse contexto.\n",
    "\n",
    "Se uma pergunta não fizer sentido ou não for factualmente coerente, faça perguntas para entender o contexto, mas nao responda de forma alguma algo incorreto. Se você não souber a resposta para uma pergunta, não compartilhe informações falsas.\n",
    "<</SYS>>\n",
    "\n",
    "Context: \n",
    "{context}\n",
    "\n",
    "Question: {question} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "llm =  VLLMOpenAI(\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base=INFERENCE_SERVER_URL,\n",
    "    model_name=MODEL_NAME,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    top_p=TOP_P,\n",
    "    temperature=TEMPERATURE,\n",
    "    presence_penalty=PRESENCE_PENALTY,\n",
    "    streaming=True,\n",
    "    verbose=False,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=store.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 4}\n",
    "            ),\n",
    "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "        return_source_documents=True\n",
    "        )\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45ad23",
   "metadata": {},
   "source": [
    "#### Query example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "105d2fd1-f36c-409d-8e52-ec6d23a56ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<</SYS>>\n",
      "\n",
      "Context: \n",
      "# SOLICITAR EMISSÃO DE 2ª VIA DE IPTU - LAURO DE FREITAS\n",
      "\n",
      "#### Sobre\n",
      "SOLICITAR EMISSÃO DE 2ª VIA DE IPTU - LAURO DE FREITAS\n",
      "\n",
      "## Documentos Necessários\n",
      "\n",
      "### DESCRIÇÃO DO SERVIÇO  \n",
      "Serviço destinado aos cidadãos que desejam obter a Emissão de 2º Via de IPTU do município de Lauro de Freitas.  \n",
      "  \n",
      "O IPTU é um imposto que incide sobre a propriedade, domínio útil ou posse imobiliária urbana, tanto para pessoas físicas, como para jurídicas. Com alíquota definida em lei municipal e benefício de desconto, definido no calendário fiscal.  \n",
      "  \n",
      "### PRÉ-REQUISITO DO SERVIÇO\n",
      "\n",
      "01. O Requerente deve possuir senha na PLATAFORMA BA.GOV.BR ou no PORTAL GOV.BR e efetuar o login.  \n",
      "  \n",
      "### QUEM PODE SOLICITAR  \n",
      "01. Negócios/Empresas;  \n",
      "02. Cidadão.  \n",
      "  \n",
      "### OUTROS NOMES PELOS QUAIS O SERVIÇO É CONHECIDO  \n",
      "EMISSÃO DE SEGUNDA VIA DE IPTU 2024  \n",
      "  \n",
      "### AGENDAMENTO  \n",
      "Não se aplica.\n",
      "\n",
      "## Informações Adicionais\n",
      "\n",
      "#### INFORMAÇÕES ADICIONAIS  \n",
      "Não se aplica.  \n",
      "  \n",
      "#### PRAZO DE ENTREGA/CONCLUSÃO DO SERVIÇO  \n",
      "De imediato.  \n",
      "  \n",
      "#### FALE CONOSCO  \n",
      "Ouvidoria da SEFAZ Lauro de Freitas  \n",
      "Telefone: 0800 284 7701  \n",
      "E-mail:ouvidoria@laurodefreitas.ba.gov.br\n",
      "\n",
      "#### Taxas/Multas\n",
      "\n",
      "VALOR DECLARADO PELO ÓRGÃO  \n",
      "Não se aplica.  \n",
      "Informação atualizada em 05/2024\n",
      "\n",
      "Question: Qual é o passo a passo para preparar uma receita de cenoura [INST]?\n",
      "<</SYS>>\n",
      "\n",
      "Context: \n",
      "# SOLICITAR EMISSÃO DE 2ª VIA DE IPTU - LAURO DE FREITAS\n",
      "\n",
      "#### Sobre\n",
      "SOLICITAR EMISSÃO DE 2ª VIA DE IPTU - LAURO DE FREITAS\n",
      "\n",
      "## Documentos Necessários\n",
      "\n",
      "### DESCRIÇÃO DO SERVIÇO  \n",
      "SERVIDOR DE EMISSÃO DE 2ª VIA DE IPTU - LAURO DE FREITAS\n",
      "\n",
      "## Próximos Passos:\n",
      "\n",
      "1. **Crie uma conta bancária**.\n",
      "2. **Crie uma conta de débito**.\n",
      "3. **Crie uma conta de crédito**.\n",
      "4. **Crie uma conta de débito**.\n",
      "5. **Crie uma conta de débito**.\n",
      "6. **Crie uma conta de débito**.\n",
      "7. **Crie uma conta de débito**.\n",
      "8. **Crie uma conta de débito**.\n",
      "9. **Crie uma conta de débito**.\n",
      "10. **Crie uma conta de débito**.\n",
      "11. **Crie uma conta de débito**.\n",
      "12. **Crie uma conta de débito**.\n",
      "13. **Crie uma conta de débito**.\n",
      "14. **Crie uma conta de débito**.\n",
      "15. **Crie uma conta de débito**.\n",
      "16. **Crie uma conta de débito**.\n",
      "17. **Crie uma conta de débito**.\n",
      "18. **Crie uma conta de débito**.\n",
      "19. **Crie uma conta de débito**.\n",
      "20. **Crie uma conta de débito**.\n",
      "21. **Crie uma conta de débito**.\n",
      "22. **Crie uma conta de débito**.\n",
      "23. **Crie uma conta de débito**.\n",
      "24. **Crie uma conta de débito**.\n",
      "25. **Crie uma conta de débito**.\n",
      "26. **Crie uma conta de débito**.\n",
      "27. **Crie uma conta de débito**.\n",
      "28. **Crie uma conta de débito**.\n",
      "29. **Crie uma conta de débito**.\n",
      "30. **Crie uma conta de débito**.\n",
      "31. **Crie uma conta de débito**.\n",
      "32. **Crie uma conta de débito**.\n",
      "33. **C"
     ]
    }
   ],
   "source": [
    "question = \"Qual o passo a passo para um bolo de cenoura\"\n",
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d75d0c",
   "metadata": {},
   "source": [
    "#### Retrieve source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acda357e-558a-4879-8ad8-21f0567f2f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "markdown/IPTU.md\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates(input_list):\n",
    "    unique_list = []\n",
    "    for item in input_list:\n",
    "        if item.metadata['source'] not in unique_list:\n",
    "            unique_list.append(item.metadata['source'])\n",
    "    return unique_list\n",
    "\n",
    "results = remove_duplicates(result['source_documents'])\n",
    "\n",
    "for s in results:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e11f24-de86-468f-a641-c34ad1d1ff54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
